{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para Google Colaboratory (Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbbL3ncEmbg9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1463,
     "status": "ok",
     "timestamp": 1538754816376,
     "user": {
      "displayName": "David Ascencios Rondón",
      "photoUrl": "",
      "userId": "04308483788421708049"
     },
     "user_tz": 300
    },
    "id": "1C3ICnsYiXuA",
    "outputId": "48443350-073e-45b6-f4b8-4bf071c4163a"
   },
   "outputs": [],
   "source": [
    "#Deiv ruta\n",
    "!ls \"drive/My Drive/ML-20182/Notebooks/Training\"\n",
    "\n",
    "train_path = '/content/drive/My Drive/2018-2/Aprendiza de máquina/ML-20182/Notebooks/Training'\n",
    "#!unzip -uq \"drive/My Drive/ML-20182/Dataset&Papers/Dataset/fruits.zip\" -d \"drive/My Drive/ML-20182/Notebooks/Unzipeado/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2043,
     "status": "ok",
     "timestamp": 1538710196438,
     "user": {
      "displayName": "JORGE ENRIQUE ESPINOZA MUÑOZ",
      "photoUrl": "",
      "userId": "01443437192001020192"
     },
     "user_tz": 300
    },
    "id": "jxELhIwHwqoA",
    "outputId": "5f8d6e28-f400-41ca-c889-e5f5d9c057f2"
   },
   "outputs": [],
   "source": [
    "#Jorge ruta\n",
    "ls -1 | wc -l '/content/drive/My Drive/2018-2/Aprendiza de máquina/ML-20182/Notebooks/Training/'\n",
    "\n",
    "train_path = '/content/drive/My Drive/2018-2/Aprendiza de máquina/ML-20182/Notebooks/Training'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para Github (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE  readme.md  Test  test-multiple_fruits\tTraining\r\n"
     ]
    }
   ],
   "source": [
    "#path\n",
    "!ls ../data/\n",
    "\n",
    "train_path_str = '../data/Training'\n",
    "test_path_str = '../data/Test'\n",
    "img_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VhezFB3aiXuP"
   },
   "source": [
    "# Imágenes - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATpdeW4xiXuS"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1538745928760,
     "user": {
      "displayName": "David Ascencios Rondón",
      "photoUrl": "",
      "userId": "04308483788421708049"
     },
     "user_tz": 300
    },
    "id": "tgvagcwZzAZ_",
    "outputId": "1483bfb8-3ab2-4e36-8776-ffeaf3d3ce95"
   },
   "outputs": [],
   "source": [
    "##Extrayendo las categorias\n",
    "\n",
    "def extract_categories(path_str):\n",
    "    path = Path(path_str)\n",
    "    categories = []\n",
    "    for index, e in enumerate(path.iterdir()):\n",
    "        categories.append((index, e))\n",
    "    return categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extrayendo las categorias (test)\n",
    "\n",
    "categories_train = extract_categories(train_path_str)\n",
    "categories_test = extract_categories(test_path_str)\n",
    "\n",
    "print('Clases en Train: ', len(categories_train))\n",
    "print('Clases en Test: ', len(categories_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisamos que está en orden\n",
    "\n",
    "#train\n",
    "\n",
    "categories_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "categories_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conteo de imágenes por Training y Testing\n",
    "\n",
    "def count_images(categories):\n",
    "    count = 0\n",
    "    for i,path in categories:\n",
    "        fruit_path = Path(path)\n",
    "        for img_fruit in fruit_path.iterdir():\n",
    "            count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos cantidad de imagenes para cada set  (deberían ser 41322 y 13877, por info del repo de GitHub)\n",
    "print('La cantidad de imágenes para  el train es ', count_images(categories_train))\n",
    "print('La cantidad de imágenes para  el test es ', count_images(categories_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1aLQGgARiXuZ"
   },
   "outputs": [],
   "source": [
    "# Tamaño del training set: 41322 imgs\n",
    "train_size = count_images(categories_train)\n",
    "\n",
    "# Tamaño del test set: 13877 imgs\n",
    "test_size = count_images(categories_test)\n",
    "\n",
    "# Primero inicializamos los arrays que vamos a usar\n",
    "x_train = np.ndarray(shape=(train_size, img_size, img_size,3), dtype=np.float32)\n",
    "y_train = np.zeros(shape=(train_size), dtype=np.int8)\n",
    "x_val = np.ndarray(shape=(test_size, img_size, img_size,3), dtype=np.float32)\n",
    "y_val = np.zeros(shape=(test_size), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1403,
     "status": "ok",
     "timestamp": 1538745937849,
     "user": {
      "displayName": "David Ascencios Rondón",
      "photoUrl": "",
      "userId": "04308483788421708049"
     },
     "user_tz": 300
    },
    "id": "92nggiJ3iXuX",
    "outputId": "fb7ee1a0-2e41-4a55-d670-fb9f55ad8cc9"
   },
   "outputs": [],
   "source": [
    "# Definimos una funcion para leer una imagen y hacer el preprocesamiento\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "def read_img(path):\n",
    "    x = Image.open(path)\n",
    "    x = x.resize((img_size, img_size))\n",
    "    x = np.asarray(x, np.float32)\n",
    "    return preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1648,
     "status": "error",
     "timestamp": 1538751259266,
     "user": {
      "displayName": "David Ascencios Rondón",
      "photoUrl": "",
      "userId": "04308483788421708049"
     },
     "user_tz": 300
    },
    "id": "8NghKXIHiXuc",
    "outputId": "3fc3f3ce-9e31-4051-a19f-568a22bff800"
   },
   "outputs": [],
   "source": [
    "# Cargamos el train set\n",
    "global_index = 0\n",
    "for i,path in categories_train:\n",
    "    print(i,path)\n",
    "    \n",
    "    train_path = Path(path)\n",
    "    for index, e in enumerate(train_path.iterdir()):\n",
    "      #print(global_index)\n",
    "      x_train[global_index] = read_img(e)\n",
    "      y_train[global_index] = i\n",
    "      global_index += 1\n",
    "print(len(x_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ZbR5bj1iXuf"
   },
   "outputs": [],
   "source": [
    "# Cargamos el test set\n",
    "global_index = 0\n",
    "for i,path in categories_test:\n",
    "    print(i,path)\n",
    "    \n",
    "    test_path = Path(path)\n",
    "    imagenes = []\n",
    "    for index, e in enumerate(test_path.iterdir()):\n",
    "      #print(global_index)\n",
    "      x_test[global_index] = read_img(e)\n",
    "      y_test[global_index] = i\n",
    "      global_index += 1\n",
    "print(len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9IejjnjiXui"
   },
   "source": [
    "# Cargamos una red entrenada\n",
    "Vamos a cargar la red **ResNet50** ya entrenada, pero sin incluir las capas densas, ya que vamos a adaptar la red a nuestro caso específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZX0eIHxfiXuj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davicin/UtilsGeneral/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "66658304/94653016 [====================>.........] - ETA: 32s"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "base_model = ResNet50(include_top=False, input_shape=(img_size,img_size,3), pooling='avg')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhhteQshiXuo"
   },
   "outputs": [],
   "source": [
    "base_model.input, base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FrW_IaWqiXus"
   },
   "outputs": [],
   "source": [
    "# Dado que solo queremos entrenar las capas densas del modelo que agregaremos\n",
    "# en el siguiente paso, vamos a setear \"trainable = False\" para que los pesos\n",
    "# de la red entrenada no cambien.\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-qEhprMiXuw"
   },
   "source": [
    "# Creamos el modelo clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHgW_OyNiXuy"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "top_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(2048,)),\n",
    "    Dense(1, activation='softmax')\n",
    "])\n",
    "\n",
    "top_model.compile(SGD(lr, momentum=0.9), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2__yu7LiXu2"
   },
   "source": [
    "# Juntamos los 2 modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqwG8QrMiXu3"
   },
   "outputs": [],
   "source": [
    "final_model = Sequential([base_model, top_model])\n",
    "\n",
    "final_model.compile(SGD(lr, momentum=0.9),loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJaERFY9iXu7"
   },
   "source": [
    "# Entrenando en nuestro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y811jTohiXu7"
   },
   "outputs": [],
   "source": [
    "# log = final_model.fit(x_train, y_train, batch_size=64, validation_data=[x_val, y_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PwLY2wnUiXu9"
   },
   "source": [
    "La red de base que estamos usando (ResNet50) tiene bastantes capas y hacer todas estas operaciones toma un tiempo considerable, en CPU hacer este entrenamiento puede resultar impractico.\n",
    "# Precompute\n",
    "Si tenemos en cuenta que vamos a entrenar nuestro dataset un cierto número de épocas, en cada época se van a repetir exactamente las mismas operaciones en la misma data. Para no redundar, es bastante útil hacer un precompute de la data:\n",
    "1. Pasar todas nuestras imagenes por la red base (ResNet50).\n",
    "2. Guardamos los features extraidos.\n",
    "3. Entrenamos las capas densas con los features extraidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uoTw6dOCiXu-"
   },
   "outputs": [],
   "source": [
    "precomputed_train = base_model.predict(x_train, batch_size=128, verbose=1)\n",
    "precomputed_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xw25nEJiiXvA"
   },
   "outputs": [],
   "source": [
    "precomputed_val = base_model.predict(x_val, batch_size=128, verbose=1)\n",
    "precomputed_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zHSYQjRwiXvD"
   },
   "source": [
    "# Entrenar a partir de los features extraidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imBa2G6jiXvE"
   },
   "outputs": [],
   "source": [
    "# Ahora podemos usar un batch_size mas grande, ya que los features son mas pequeños\n",
    "# que las imagenes.\n",
    "log = top_model.fit(precomputed_train, y_train, epochs=5, batch_size=256, validation_data=[precomputed_val, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onGqywijiXvG"
   },
   "outputs": [],
   "source": [
    "def show_results(log):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14,4))\n",
    "    ax1, ax2 = axes\n",
    "    ax1.plot(log.history['loss'], label='train')\n",
    "    ax1.plot(log.history['val_loss'], label='validation')\n",
    "    ax1.set_xlabel('epoch'); ax1.set_ylabel('loss')\n",
    "    ax2.plot(log.history['acc'], label='train')\n",
    "    ax2.plot(log.history['val_acc'], label='validation')\n",
    "    ax2.set_xlabel('epoch'); ax2.set_ylabel('accuracy')\n",
    "    for ax in axes: ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i2DOfUNCiXvK"
   },
   "outputs": [],
   "source": [
    "show_results(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9A5_HVEmiXvO"
   },
   "source": [
    "# Ejercicio: usando el modelo completo en el test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6RVIEOJeiXvP"
   },
   "outputs": [],
   "source": [
    "test_path = Path('../input/test/')\n",
    "test_files = list(test_path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxHob6YBiXvR"
   },
   "outputs": [],
   "source": [
    "def get_class(path):\n",
    "    # Cargar la imagen del path\n",
    "    img = Image.open(path)\n",
    "    \n",
    "    # Cambiar el tamaño de la imagen\n",
    "    img_resized = img.resize((224, 224))\n",
    "    \n",
    "    # Cambiar a formato numpy y preprocesar\n",
    "    x = np.asarray(img_resized, np.float32)[None]\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    y = final_model.predict(x)\n",
    "    \n",
    "    # Decodear predicciones\n",
    "    pred = 'cat' if y < 0.5 else 'dog'\n",
    "    \n",
    "    # Mostrar la imagen\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(pred, size=14)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "viEz71EhiXvT"
   },
   "outputs": [],
   "source": [
    "sample = np.random.choice(test_files)\n",
    "get_class(sample)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ConvNet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
